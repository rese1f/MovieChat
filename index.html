---
layout: page
title: "<font color=Pink>MovieChat</font>: From Dense Token to Sparse Memory in Long Video Understanding"
subtitle: "MovieChat Team"
bigimg: "static/imgs/cover.png"
use-site-title: true
---

<head>
	<script src="https://kit.fontawesome.com/5bef57b3e9.js" crossorigin="anonymous"></script>
</head>

Recently, integrating video foundation models and large language models to build a video understanding system overcoming the limitations of specific pre-defined vision tasks. Yet, existing systems can only handle videos with limited and very few frames. For long videos, the computation complexity, memory cost, and long-term temporal connection are the remaining challenges. Inspired by Atkinson-Shiffrin memory model, we develop an memory mechanism including a rapidly updated short-term memory and a compact thus sustained long-term memory. We employ tokens in Transformers as the carriers of memory. MovieChat achieves state-of-the-art performace in long video understanding.

<br>
<br>

<b>We are waiting for you!</b> We currently have 2 master students with 2 professors as advisor. We plan to have several (3+) more undergradutes involved.

<br>
<br>

<b><i class="fa-solid fa-pen-to-square" style="font-size:24px"></i> We expect you have:</b>

<ul>
	<li> Motivation to do research.
	</li>
</ul>

<b><i class="fa-solid fa-pen-to-square" style="font-size:24px"></i> We could give you:</b>

<ul>
	<li> Careful guidance to start your research.
	</li>

	<li> Sufficient computation resource to implement your idea.
	</li>

	<li> Listing in our research paper if you make core contribution!
	</li>
</ul>

<b><i class="fa-solid fa-pen-to-square" style="font-size:24px"></i> We want you to:</b>
<ul>
	<li> Collecting long video question-auswering pairs data.
	</li>
	<li> Helping training and testing <b>Steve</b> with collected data.
	</li>
</ul>


Contact Prof. Wang or me (wchai@uw.edu) if you are interested in this project.
